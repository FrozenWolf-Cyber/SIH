{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.transforms import transforms as T\n",
    "from seesawfacenet_pytorch.src.seesaw_models import seesaw_shareFaceNet, seesaw_shuffleFaceNet, DW_seesawFaceNetv2\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.pre_process = T.Compose([T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "        self.backbone = model\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pre_process(x)\n",
    "        return self.backbone(x)\n",
    "\n",
    "def get_seesawnet_model(model, saved_dict):\n",
    "    # saved_dict = torch.load(\"saved_models/Seesaw-shuffleFaceNet_160bs/save/model_2019-06-22-17-20_accuracy_0.9184285714285714_step_568064_final.pth\", map_location=\"cuda\")\n",
    "    saved_dict = {v[7:]:k for v,k in saved_dict.items()}\n",
    "    model.load_state_dict(saved_dict)\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "\n",
    "    seesawnet_model = CustomNet(model)\n",
    "    seesawnet_model.eval()\n",
    "\n",
    "    img = Image.open(\"img.jpg\")\n",
    "    img = torch.FloatTensor(cv2.resize(np.asarray(img), (112, 112))).permute(2,0,1)\n",
    "    img = img/255.\n",
    "    img = img.unsqueeze(0)\n",
    "    out = model(img)\n",
    "\n",
    "    return seesawnet_model\n",
    "\n",
    "reimplement_model_seesawnet = CustomNet(torch.jit.load(\"saved_models/Seesaw_shuffleFaceNet.pt\", map_location=\"cuda\")).cuda().eval()\n",
    "\n",
    "models_configs = [(\"reimplementation_seesawnet\",reimplement_model_seesawnet,None),\n",
    "                 (\"seesaw_shuffleFaceNet_160\", seesaw_shuffleFaceNet.seesaw_shuffleFaceNet(512), \"saved_models/Seesaw-shuffleFaceNet_160bs/save/model_2019-06-22-17-20_accuracy_0.9184285714285714_step_568064_final.pth\"),\n",
    "                 (\"seesaw_shuffleFaceNet_192\", seesaw_shuffleFaceNet.seesaw_shuffleFaceNet(512), \"saved_models/Seesaw-shuffleFaceNet_192bs/save/model_2019-06-14-06-06_accuracy_0.9269999999999999_step_475328_final.pth\"),\n",
    "                 (\"seesaw_shareFaceNet_160\", seesaw_shareFaceNet.seesaw_shareFaceNet(512), \"saved_models/Seesaw-shareFaceNet_160bs/save/model_2019-06-19-04-38_accuracy_0.9298571428571428_step_568064_final.pth\"),\n",
    "                 (\"DW_seesawFaceNetv2\", DW_seesawFaceNetv2.DW_seesawFaceNetv2(512), \"saved_models/DW-SeesawFaceNetv2_128bs/save/model_2019-08-03-07-50_accuracy_0.9486000000000001_step_727840_final.pth\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeds(path, model):\n",
    "    img = Image.open(path)\n",
    "    img = torch.FloatTensor(cv2.resize(np.asarray(img), (112, 112))).permute(2,0,1)\n",
    "    img = img/255.\n",
    "\n",
    "    return model(img.unsqueeze(0).cuda()).cpu().detach().numpy()[0]\n",
    "\n",
    "\n",
    "\n",
    "path = \"dataset/lfw_funneled\"\n",
    "\n",
    "img_names = os.listdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_path = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i[-3:] == \"txt\":\n",
    "        continue\n",
    "    for j in os.listdir(path+'/'+i):\n",
    "        if \"ipynb_checkpoints\" in j:\n",
    "            continue\n",
    "        all_img_path.append([i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ImgGenDataset(Dataset):\n",
    "  def __init__(self, x):\n",
    "      self.x = x\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.x)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      img = Image.open(path+'/'+'/'.join(self.x[idx]))\n",
    "      img = torch.FloatTensor(cv2.resize(np.asarray(img), (112, 112))).permute(2,0,1)\n",
    "      img = img/255.\n",
    "\n",
    "      return img, self.x[idx]\n",
    "\n",
    "imgdataset = ImgGenDataset(all_img_path)\n",
    "ImgGenerator = DataLoader(imgdataset, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Aaron_Eckhart_0001.jpg',\n",
       " 'Aaron_Guiel_0001.jpg',\n",
       " 'Aaron_Patterson_0001.jpg',\n",
       " 'Aaron_Peirsol_0001.jpg',\n",
       " 'Aaron_Peirsol_0002.jpg',\n",
       " 'Aaron_Peirsol_0003.jpg',\n",
       " 'Aaron_Peirsol_0004.jpg',\n",
       " 'Aaron_Pena_0001.jpg',\n",
       " 'Aaron_Sorkin_0001.jpg',\n",
       " 'Aaron_Sorkin_0002.jpg',\n",
       " 'Aaron_Tippin_0001.jpg',\n",
       " 'Abbas_Kiarostami_0001.jpg',\n",
       " 'Abba_Eban_0001.jpg',\n",
       " 'Abdel_Aziz_Al-Hakim_0001.jpg',\n",
       " 'Abdel_Madi_Shabneh_0001.jpg',\n",
       " 'Abdel_Nasser_Assidi_0001.jpg',\n",
       " 'Abdel_Nasser_Assidi_0002.jpg',\n",
       " 'Abdoulaye_Wade_0001.jpg',\n",
       " 'Abdoulaye_Wade_0002.jpg',\n",
       " 'Abdoulaye_Wade_0003.jpg',\n",
       " 'Abdoulaye_Wade_0004.jpg',\n",
       " 'Abdulaziz_Kamilov_0001.jpg',\n",
       " 'Abdullah_0001.jpg',\n",
       " 'Abdullah_0002.jpg',\n",
       " 'Abdullah_0003.jpg',\n",
       " 'Abdullah_0004.jpg',\n",
       " 'Abdullah_Ahmad_Badawi_0001.jpg',\n",
       " 'Abdullah_al-Attiyah_0002.jpg',\n",
       " 'Abdullah_al-Attiyah_0003.jpg',\n",
       " 'Abdullah_Gul_0001.jpg',\n",
       " 'Abdullah_Gul_0002.jpg',\n",
       " 'Abdullah_Gul_0003.jpg',\n",
       " 'Abdullah_Gul_0004.jpg',\n",
       " 'Abdullah_Gul_0005.jpg',\n",
       " 'Abdullah_Gul_0006.jpg',\n",
       " 'Abdullah_Gul_0007.jpg',\n",
       " 'Abdullah_Gul_0008.jpg',\n",
       " 'Abdullah_Gul_0009.jpg',\n",
       " 'Abdullah_Gul_0010.jpg',\n",
       " 'Abdullah_Gul_0011.jpg',\n",
       " 'Abdullah_Gul_0012.jpg',\n",
       " 'Abdullah_Gul_0013.jpg',\n",
       " 'Abdullah_Gul_0014.jpg',\n",
       " 'Abdullah_Gul_0015.jpg',\n",
       " 'Abdullah_Gul_0016.jpg',\n",
       " 'Abdullah_Gul_0017.jpg',\n",
       " 'Abdullah_Gul_0018.jpg',\n",
       " 'Abdullah_Gul_0019.jpg',\n",
       " 'Abdullah_Nasseef_0001.jpg',\n",
       " 'Abdullatif_Sener_0001.jpg',\n",
       " 'Abdullatif_Sener_0002.jpg',\n",
       " 'Abdul_Majeed_Shobokshi_0001.jpg',\n",
       " 'Abdul_Rahman_0001.jpg',\n",
       " 'Abel_Aguilar_0001.jpg',\n",
       " 'Abel_Pacheco_0001.jpg',\n",
       " 'Abel_Pacheco_0002.jpg',\n",
       " 'Abel_Pacheco_0003.jpg',\n",
       " 'Abel_Pacheco_0004.jpg',\n",
       " 'Abid_Hamid_Mahmud_Al-Tikriti_0001.jpg',\n",
       " 'Abid_Hamid_Mahmud_Al-Tikriti_0002.jpg',\n",
       " 'Abid_Hamid_Mahmud_Al-Tikriti_0003.jpg',\n",
       " 'Abner_Martinez_0001.jpg',\n",
       " 'Abraham_Foxman_0001.jpg',\n",
       " 'Aby_Har-Even_0001.jpg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ImgGenerator))[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reimplementation_seesawnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [02:53<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seesaw_shuffleFaceNet_160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:48<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seesaw_shuffleFaceNet_192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:45<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seesaw_shareFaceNet_160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:52<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DW_seesawFaceNetv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [01:55<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "for name,model,saved_dict_path in models_configs:\n",
    "    print(name)\n",
    "    if saved_dict_path == None:\n",
    "        model = model\n",
    "\n",
    "    else:\n",
    "        model = get_seesawnet_model(model, torch.load(saved_dict_path))\n",
    "\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    if f\"embeddings_{name}\" not in os.listdir():\n",
    "        os.mkdir(f\"embeddings_{name}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, path_info in tqdm(ImgGenerator):\n",
    "            img = img.cuda()\n",
    "            out = model(img)\n",
    "\n",
    "            for i,j,k in zip(out.detach().cpu().numpy(), path_info[0], path_info[1]):\n",
    "                if j not in os.listdir(f\"embeddings_{name}\"):\n",
    "                    os.mkdir(f\"embeddings_{name}/{j}\")\n",
    "\n",
    "                np.save(f\"embeddings_{name}/{j}/{k}.npy\", i)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.06436"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist(np.load(\"embeddings_reimplementation_seesawnet\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg.npy\"), np.load(\"embeddings_reimplementation_seesawnet\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.5492"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist(np.load(\"embeddings_reimplementation_seesawnet\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg.npy\"), np.load(\"embeddings_reimplementation_seesawnet\\Aaron_Patterson\\Aaron_Patterson_0001.jpg.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070517"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist(np.load(\"embeddings_DW_seesawFaceNetv2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg.npy\"), np.load(\"embeddings_DW_seesawFaceNetv2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.31352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist(np.load(\"embeddings_DW_seesawFaceNetv2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg.npy\"), np.load(\"embeddings_DW_seesawFaceNetv2\\Aaron_Patterson\\Aaron_Patterson_0001.jpg.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
